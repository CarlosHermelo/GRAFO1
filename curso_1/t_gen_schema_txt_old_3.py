import os
import glob
import json
from typing import List, Tuple, Set, Dict
from openai import OpenAI
from pydantic import BaseModel, Field
from dotenv import load_dotenv

# Carga variables de entorno (asume que OPENAI_API_KEY estÃ¡ en un archivo .env)
load_dotenv()
client = OpenAI()

# --- CONFIGURACIÃ“N DEL PROYECTO ---
FOLDER_PATH = r"C:\Users\u14527001\Downloads\grafo_protesis\curso_1"

#  - Definimos el objetivo para filtrar entidades irrelevantes
USER_GOAL = """
Construir un Grafo de Conocimiento clÃ­nico que permita analizar de manera integrada el contenido de mÃºltiples guÃ­as mÃ©dicas, identificar relaciones entre enfermedades, tratamientos, factores de riesgo y complicaciones, y responder preguntas complejas basadas en comorbilidades.

objetivos especÃ­ficos

Identificar vÃ­nculos clÃ­nicos fundamentales entre entidades mÃ©dicas, tales como:
â€¢ asociaciÃ³n causal (FactorRiesgo â†’ Enfermedad)
â€¢ indicaciÃ³n terapÃ©utica (Enfermedad â†’ Tratamiento)
â€¢ contraindicaciÃ³n o ajuste (Tratamiento â†’ CondiciÃ³n)
â€¢ progresiÃ³n o complicaciÃ³n (Enfermedad â†’ ComplicaciÃ³n)

Representar coherentemente la estructura clÃ­nica de cada guÃ­a:
â€¢ criterios diagnÃ³sticos
â€¢ clasificaciones (GOLD, KDIGO, grados de hipertensiÃ³n, etc.)
â€¢ recomendaciones segÃºn severidad
â€¢ decisiones terapÃ©uticas dependientes de otras enfermedades

Integrar entidades que aparecen en diferentes guÃ­as y que deben unificarse en un Ãºnico espacio semÃ¡ntico:
â€¢ patologÃ­as compartidas
â€¢ tratamientos utilizados en varias condiciones
â€¢ factores de riesgo comunes
â€¢ complicaciones que conectan mÃºltiples enfermedades

criterios de exclusiÃ³n

Ignorar detalles administrativos o logÃ­sticos que no afecten el razonamiento clÃ­nico:
â€¢ nombres propios de instituciones
â€¢ direcciones
â€¢ datos anecdÃ³ticos sin impacto en diagnÃ³stico, tratamiento o evoluciÃ³n
â€¢ valores no estandarizados sin relaciÃ³n explÃ­cita con decisiones clÃ­nicas

tres entidades representativas

Enfermedad: â€œDiabetes tipo 2â€

Tratamiento: â€œIECAâ€

ComplicaciÃ³n: â€œInsuficiencia renal crÃ³nicaâ€

"""

# [cite: 439, 454] - Etiquetas conocidas para estandarizar el grafo desde el principio
WELL_KNOWN_LABELS = ["Enfermedad", "Tratamiento", "CondiciÃ³n", "ComplicaciÃ³n", "FactorRiesgo"]


# --- 1. Carga de Archivos ---
def read_txt_files(folder_path: str) -> Dict[str, str]:
    """Lee todos los archivos .txt de la ruta especificada."""
    files_content = {}
    search_path = os.path.join(folder_path, "*.txt")
    files = glob.glob(search_path)
    
    print(f"ðŸ“‚ Buscando archivos en: {folder_path}")
    if not files:
        print("âš ï¸ No se encontraron archivos .txt.")
        return {}

    for file_path in files:
        file_name = os.path.basename(file_path)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                files_content[file_name] = f.read()
                print(f"  âœ… Cargado: {file_name}")
        except Exception:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    files_content[file_name] = f.read()
                    print(f"  âœ… Cargado (latin-1): {file_name}")
            except Exception as e:
                print(f"  âŒ Error leyendo {file_name}: {e}")
    return files_content

# --- 2. Modelos de Datos (Pydantic) ---

class SchemaDefinition(BaseModel):
    node_labels: List[str] = Field(description="Lista de tipos de nodos GENERALES (ej. 'Resolucion', 'Organismo').")
    relationship_types: List[str] = Field(description="Lista de verbos/relaciones posibles (ej. 'DEROGA', 'EMITE').")

class GraphNode(BaseModel):
    id: str = Field(description="Identificador Ãºnico y limpio (SNAKE_CASE_MAYUSCULA) para el nodo.")
    label: str = Field(description="El tipo de nodo (debe coincidir con el esquema aprobado).")
    properties: str = Field(description="Resumen corto o nombre descriptivo del nodo.")

class GraphRelationship(BaseModel):
    source_id: str = Field(description="ID del nodo origen.")
    source_label: str = Field(description="Label del nodo origen.")
    relationship: str = Field(description="Tipo de relaciÃ³n (UPPERCASE).")
    target_id: str = Field(description="ID del nodo destino.")
    target_label: str = Field(description="Label del nodo destino.")

class ExtractionResult(BaseModel):
    nodes: List[GraphNode]
    relationships: List[GraphRelationship]

# --- 3. Agentes (OntÃ³logo y Extractor) ---

def run_ontology_agent(text_content: str, goal: str, known_labels: List[str]) -> Tuple[SchemaDefinition, int]:
    """
    Fase 1: Descubre el esquema abstracto basÃ¡ndose en el objetivo y etiquetas conocidas.
    [cite: 405, 407] - Analiza archivos buscando tipos de entidades relevantes.
    """
    system_prompt = f"""
    Eres un Arquitecto de Datos experto en Neo4j.
    Tu tarea es definir el ESQUEMA (Labels y Relaciones) para un Grafo de Conocimiento.
    
    OBJETIVO DEL USUARIO: {goal}
    ENTIDADES CONOCIDAS (Ãšsalas si aplican): {known_labels}
    
    REGLAS:
1. Todas las entidades, labels, tipos de nodos y nombres deben estar EN CASTELLANO.
2. Todas las relaciones deben estar EN CASTELLANO y en MAYÃšSCULAS (ej. FACTOR_DE_RIESGO_DE, COMPLICA, INDICA_TRATAMIENTO, ASOCIA_A).
3. Nunca uses verbos ni labels en inglÃ©s. No usar: RESULTS_IN_COMPLICATION, CAUSES, HAS, TREATS, etc.
4. Usa CamelCase para los nombres de nodos (ej. Enfermedad, CriterioDiagnostico, FactorRiesgo).
5. Usa UPPER_CASE con guiones bajos para relaciones (ej. PRODUCE_COMPLICACION, INDICA, SE_ASOCIA_CON).
6. Usa solo las entidades relevantes para el objetivo clÃ­nico.



    """
    
    content_sample = text_content[:15000] # Muestra representativa
    
    completion = client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Analiza este texto y define el esquema:\n{content_sample}"},
        ],
        response_format=SchemaDefinition,
    )
    
    schema = completion.choices[0].message.parsed
    tokens = completion.usage.total_tokens
    
    print(f"  [ONTÃ“LOGO] ðŸ“ˆ Tokens: {tokens} | Labels: {len(schema.node_labels)} | Rels: {len(schema.relationship_types)}")
    return schema, tokens

def run_extraction_agent(text_content: str, schema: SchemaDefinition) -> Tuple[ExtractionResult, int]:
    """
    Fase 2: Extrae instancias usando el esquema maestro unificado.
    [cite: 410, 411] - Usa el contexto aprobado para extraer tripletas.
    """
    system_prompt = f"""
    Eres un experto en extracciÃ³n de Grafos.
    Tu objetivo es extraer instancias reales del texto basÃ¡ndote EXCLUSIVAMENTE en este esquema UNIFICADO:
    
    Nodos permitidos: {schema.node_labels}
    Relaciones permitidas: {schema.relationship_types}
    
   INSTRUCCIONES:
1. Todos los labels de nodos deben estar en castellano y en CamelCase (ej. Enfermedad, Tratamiento, ComplicaciÃ³n, FactorRiesgo).
2. Todas las relaciones deben estar en castellano, en MAYÃšSCULAS y con guiones bajos (ej. PRODUCE_COMPLICACION, AUMENTA_RIESGO_DE, INDICA_TRATAMIENTO).
3. No usar ninguna relaciÃ³n ni label en inglÃ©s. Nunca usar: RESULTS_IN_COMPLICATION, CAUSES, LEADS_TO, HAS, etc.
4. Genera IDs en SNAKE_CASE_MAYÃšSCULA en castellano.
5. Usa solo relaciones incluidas en el esquema pasado.
6. No inventes verbos que no sean clÃ­nicos o semÃ¡nticos. Usar expresiones naturales del castellano.

    """
    
    completion = client.beta.chat.completions.parse(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"Extrae los datos del siguiente texto:\n{text_content[:30000]}"},
        ],
        response_format=ExtractionResult,
    )
    
    result = completion.choices[0].message.parsed
    tokens = completion.usage.total_tokens

    print(f"  [EXTRACTOR] ðŸ“ˆ Tokens: {tokens} | Nodos: {len(result.nodes)} | Rels: {len(result.relationships)}")
    return result, tokens

# --- 4. Generador Cypher con Trazabilidad ---

def generate_cypher_fragment(data: ExtractionResult, filename: str) -> str:
    """Genera el bloque Cypher para un archivo, incluyendo el Grafo LÃ©xico (Documento -> Entidad)."""
    cypher_lines = []
    
    # [cite: 761] - CreaciÃ³n del nodo Documento (Lexical Graph)
    doc_id = filename.replace(".", "_").replace(" ", "_").replace("-", "_").upper()
    cypher_lines.append(f"\n// --- ARCHIVO: {filename} ---")
    cypher_lines.append(f'MERGE (d:Documento {{id: "{doc_id}"}}) ON CREATE SET d.nombre = "{filename}";')

    generated_ids: Set[str] = set()
    
    # Nodos y ConexiÃ³n LÃ©xica
    for node in data.nodes:
        if node.id and node.id not in generated_ids:
            safe_prop = node.properties.replace('"', "'")
            # Crear nodo entidad (Subject Graph)
            cypher_lines.append(f'MERGE (n:{node.label} {{id: "{node.id}"}}) ON CREATE SET n.nombre = "{safe_prop}";')
            
            # Conectar Documento con Entidad (Trazabilidad)
            cypher_lines.append(f'MATCH (d:Documento {{id: "{doc_id}"}}), (n:{node.label} {{id: "{node.id}"}}) MERGE (d)-[:MENCIONA]->(n);')
            
            generated_ids.add(node.id)
            
    # Relaciones SemÃ¡nticas (Subject Graph)
    for rel in data.relationships:
        if rel.source_id in generated_ids and rel.target_id in generated_ids:
            cypher_lines.append(f'MATCH (a:{rel.source_label} {{id: "{rel.source_id}"}}), (b:{rel.target_label} {{id: "{rel.target_id}"}}) MERGE (a)-[:{rel.relationship}]->(b);')

    return "\n".join(cypher_lines)

# --- MAIN ---

def main():
    txt_files = read_txt_files(FOLDER_PATH)
    if not txt_files: return

    # Inicializar sets y contadores
    master_node_labels: Set[str] = set(WELL_KNOWN_LABELS) # Iniciamos con lo conocido
    master_relationship_types: Set[str] = set()
    global_schema_triplets: Set[Tuple[str, str, str]] = set()
    
    total_t1 = 0
    total_t2 = 0

    # ==========================================================
    # PASE 1: DISCOVERY (Define el Esquema Maestro)
    # ==========================================================
    print("\n" + "#"*60)
    print("FASE 1: DESCUBRIMIENTO DEL ESQUEMA (OntologÃ­a)")
    print("#"*60)

    for filename, content in txt_files.items():
        print(f"\n--- ðŸ”Ž Analizando esquema en: {filename} ---")
        schema, t1 = run_ontology_agent(content, USER_GOAL, list(master_node_labels))
        total_t1 += t1
        
        # FusiÃ³n inteligente de esquemas
        master_node_labels.update(schema.node_labels)
        master_relationship_types.update(schema.relationship_types)
        
    master_schema = SchemaDefinition(
        node_labels=sorted(list(master_node_labels)),
        relationship_types=sorted(list(master_relationship_types))
    )
    
    print(f"\nâœ… Esquema Maestro Definido: {len(master_schema.node_labels)} Labels, {len(master_schema.relationship_types)} Relaciones.")

    # ==========================================================
    # PASE 2: EXTRACTION (Genera Datos y Cypher)
    # ==========================================================
    print("\n" + "#"*60)
    print("FASE 2: EXTRACCIÃ“N Y GENERACIÃ“N DE CÃ“DIGO")
    print("#"*60)
    
    full_cypher_script = []
    
    # [cite: 60, 66] - OptimizaciÃ³n: Constraints de Unicidad
    full_cypher_script.append("// --- CONSTRAINTS DE UNICIDAD (OptimizaciÃ³n) ---")
    for label in master_schema.node_labels:
        full_cypher_script.append(f"CREATE CONSTRAINT constraint_{label}_id IF NOT EXISTS FOR (n:{label}) REQUIRE n.id IS UNIQUE;")
    # Constraint para el grafo lÃ©xico
    full_cypher_script.append("CREATE CONSTRAINT constraint_Documento_id IF NOT EXISTS FOR (d:Documento) REQUIRE d.id IS UNIQUE;")

    for filename, content in txt_files.items():
        print(f"\n--- â›ï¸ Procesando archivo: {filename} ---")
        
        # 1. ExtracciÃ³n (Usando el Esquema Maestro)
        data, t2 = run_extraction_agent(content, master_schema)
        total_t2 += t2
        
        # 2. Acumular Tripletas para visualizaciÃ³n abstracta
        for rel in data.relationships:
            global_schema_triplets.add((rel.source_label, rel.relationship, rel.target_label))

        # 3. Generar fragmento Cypher
        fragment = generate_cypher_fragment(data, filename)
        full_cypher_script.append(fragment)

    # ==========================================================
    # RESULTADOS FINALES
    # ==========================================================

    # 1. IMPRESIÃ“N DEL ESQUEMA ABSTRACTO
    print("\n" + "="*60)
    print("ðŸ“¢ ESQUEMA ABSTRACTO DESCUBIERTO (TIPO --RELACIÃ“N--> TIPO)")
    print("="*60)
    if global_schema_triplets:
        for s, r, t in sorted(list(global_schema_triplets)):
            print(f"({s}) --[{r}]--> ({t})")
    else:
        print("(No se detectaron relaciones)")

    # 2. IMPRESIÃ“N DEL SCRIPT CYPHER
    final_script = "\n".join(full_cypher_script)
    
    # Opcional: Guardar en archivo
    with open("grafo_generado.cypher", "w", encoding="utf-8") as f:
        f.write(final_script)
        
    print("\n" + "="*60)
    print("ðŸ’» SCRIPT CYPHER FINAL (Primeras 20 lÃ­neas)")
    print("="*60)
    print("\n".join(final_script.split("\n")[:20]))
    print("...\n(Ver archivo completo 'grafo_generado.cypher')")
    print("="*60)
    
    # 3. Reporte Tokens
    print(f"\nðŸ’° CONSUMO TOTAL: {total_t1 + total_t2} Tokens (OntÃ³logo: {total_t1} | Extractor: {total_t2})")

if __name__ == "__main__":
    main()